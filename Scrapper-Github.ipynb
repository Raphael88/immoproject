{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "from http.cookiejar import CookieJar\n",
    "from urllib.parse import urlencode\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import date\n",
    "import time as t\n",
    "import pandas as pd\n",
    "from http.cookiejar import CookieJar\n",
    "import random\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa786ec6",
   "metadata": {},
   "source": [
    "# Scrapper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"insert here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ffb4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "## Setting up the link to scrap\n",
    "start_link = link\n",
    "list_link = []\n",
    "loop_inf = -1\n",
    "loop_sup = 1\n",
    "x = random.randint(2, 5)\n",
    "kicker = 0\n",
    "\n",
    "\n",
    "while loop_inf < loop_sup :\n",
    "    \n",
    "    same_link = False\n",
    "    \n",
    "    if kicker == 500 or same_link == True:\n",
    "        loop_inf = loop_inf\n",
    "    else:\n",
    "        loop_inf = loop_inf + 1 \n",
    "        print(\"added 1\")\n",
    "        \n",
    "    \n",
    "    ## Get the data from the starting page - Using an API to bypass security \n",
    "    params = {'api_key': 'XXX', 'url': start_link, 'params': \"....\"}\n",
    "    response = requests.get('XXXX', params=params)\n",
    "    webpage = response.text\n",
    "    soup = BeautifulSoup(webpage, 'html5lib')\n",
    "    \n",
    "\n",
    "    if response.status_code == 200 :\n",
    "        print(\"ok, proceed to grab info\")\n",
    "        print(response.status_code)\n",
    "\n",
    "        if len(soup.find_all('a', attrs={'class' : 'absolute inset-0'})) != 0:\n",
    "                # Get ad links\n",
    "                for item in soup.find_all('a', attrs={'class' : 'absolute inset-0'}):\n",
    "                    ad_link = item.get('href')\n",
    "                    list_link.append(ad_link)\n",
    "                print(\"Added links\")\n",
    "                \n",
    "\n",
    "                # Get next page  \n",
    "                for item in soup.find_all('div', attrs={'class' : 'flex w-full justify-center'}):\n",
    "                    for a in item.find_all(\"a\"):\n",
    "                        last_link = a.get(\"href\")\n",
    "                        \n",
    "                        loop_sup = int(last_link[-1])\n",
    "                        test_link = str(\"https://www.leboncoin.fr\"+str(last_link))\n",
    "                        if start_link != test_link:\n",
    "                            start_link = \"https://www.leboncoin.fr\"+str(last_link)\n",
    "                            kicker = 0\n",
    "                        else :\n",
    "                            print(\"Same link\")\n",
    "                            kicker = 0\n",
    "                            same_link = True\n",
    "                            t.sleep(x)\n",
    "                            continue\n",
    "                            \n",
    "                    print(\"new start_link : \"+ start_link)\n",
    "           \n",
    "        x = random.randint(5, 10)\n",
    "        t.sleep(x)\n",
    "        \n",
    "    elif response.status_code == 500 :\n",
    "        kicker = 500\n",
    "        print(\"scrapper encountered a problem\")\n",
    "        print(response.status_code)\n",
    "        x = random.randint(5, 10)\n",
    "        t.sleep(x)\n",
    "        continue \n",
    "        \n",
    "\n",
    "    print(\"loop_inf : \" + str(loop_inf))\n",
    "    print(\"loop_sup : \" + str(loop_sup))\n",
    "    \n",
    "print(\"Scraper finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort out doubles\n",
    "list_link = list(set(list_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bbb1f-9dbf-45ce-b6ca-d6c234ee6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7357a-764f-4435-ae4c-baa594a61a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "## Setting up the link to scrap\n",
    "\n",
    "\n",
    "count = 0\n",
    "list_ad_to_store = []\n",
    "itera = 0\n",
    "columns = [\"Type\", \"surface_h\", \"surface_t\", \"piece\", \"chambre\", \"prix\", \"id_ad\"]\n",
    "df = pd.DataFrame([], columns = columns)\n",
    "list_dim = []\n",
    "list_ad_id = []\n",
    "list_time = []\n",
    "list_desc = []\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "for ad_link in list_link:\n",
    "    if itera < len(list_link):\n",
    "        ad_link_scrap = \"https://www.leboncoin.fr\"+str(ad_link)\n",
    "        start_link = ad_link_scrap\n",
    "        ## Get the data from the starting page\n",
    "        params = {'api_key': '39dc9cd4f54af1e852b1300b785c31d1', 'url': start_link, 'device_type': 'desktop',  \"ultra_premium\" : \"true\"}\n",
    "        response = requests.get('http://api.scraperapi.com/', params=urlencode(params))\n",
    "        webpage = response.text\n",
    "        soup = BeautifulSoup(webpage, 'html5lib')\n",
    "\n",
    "        if response.status_code == 500:\n",
    "            print(\"Error 500\", response.status_code)\n",
    "            x = random.randint(15, 35)\n",
    "            t.sleep(x)\n",
    "            continue\n",
    "\n",
    "        else :\n",
    "            \n",
    "            for price in soup.find_all('p', attrs={'class' : 'text-headline-2'}):\n",
    "                pricing = str(price.text)\n",
    "            \n",
    "            for place in soup.find_all('a', attrs={'class' : 'text-body-1'}):\n",
    "                place_ad = str(place.text)\n",
    "                \n",
    "\n",
    "\n",
    "            for desc in soup.find_all('p', attrs={'class' : 'text-body-1 truncate font-bold'}):\n",
    "                if desc.text == \"\":\n",
    "                    list_desc.append(\" \")\n",
    "                    list_ad_id.append(re.sub(r'[^\\d]', '', ad_link_scrap))\n",
    "                    list_time.append(date.today().strftime(\"%Y-%m-%d-%H:%M:%S\"))\n",
    "                else:\n",
    "                    list_desc.append(desc.text)\n",
    "                    list_ad_id.append(re.sub(r'[^\\d]', '', ad_link_scrap))\n",
    "                    list_time.append(date.today().strftime(\"%Y-%m-%d-%H:%M:%S\"))\n",
    "            \n",
    "            \n",
    "            for dim in soup.find_all('p'):\n",
    "                class_string = dim.get('class')\n",
    "                if class_string == ['mb-sm', 'truncate', 'text-caption', 'opacity-dim-1'] or \\\n",
    "                   class_string == ['mb-sm', 'text-caption', 'opacity-dim-1', 'truncate']:\n",
    "\n",
    "            #for dim in soup.find_all('p', attrs={'class' : 'mb-sm truncate text-caption opacity-dim-1'}):\n",
    "                    list_dim.append(dim.text)\n",
    "                    print(str(itera)+\": \"+ dim.text)\n",
    "                \n",
    "            #count = count + 1\n",
    "\n",
    "            pricing = re.sub(r'[^\\d]', '', pricing)\n",
    "            list_desc.append(pricing)\n",
    "            list_ad_id.append(re.sub(r'[^\\d]', '', ad_link_scrap))\n",
    "            list_time.append(date.today().strftime(\"%Y-%m-%d-%H:%M:%S\"))\n",
    "            list_dim.append(\"price\")\n",
    "            \n",
    "            list_desc.append(place.text)\n",
    "            print(str(place.text))\n",
    "            list_ad_id.append(re.sub(r'[^\\d]', '', ad_link_scrap))\n",
    "            list_time.append(date.today().strftime(\"%Y-%m-%d-%H:%M:%S\"))\n",
    "            list_dim.append(\"place\")\n",
    "            \n",
    "            #df_temp = pd.DataFrame([list_desc], columns = columns)\n",
    "            #df = pd.concat([df, df_temp], ignore_index = True)\n",
    "            itera = itera + 1\n",
    "            x = random.randint(15, 35)\n",
    "            t.sleep(x)\n",
    "\n",
    "            \n",
    "            print(start_link)\n",
    "            print(\"done\")\n",
    "    else:\n",
    "        print(\"Scraper is finished\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791872f3-e39a-42e2-9431-9135d7ef6378",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ad_id': list_ad_id,\n",
    "    'time': list_time,\n",
    "    'dim': list_dim,\n",
    "    'desc': list_desc,\n",
    "})\n",
    "\n",
    "\n",
    "df_1 = df.copy()\n",
    "\n",
    "df_1.replace(\"Disponible à partir de\", \"dispo\", inplace = True)\n",
    "df_1.replace(\"Honoraires inclus\", \"Hono_inclus\", inplace = True)\n",
    "df_1.replace(\"Nombre de chambres\", \"nomb_chambre\", inplace = True)\n",
    "df_1.replace(\"Nombre de pièces\", \"nomb_piece\", inplace = True)\n",
    "df_1.replace(\"Nombre de salles d'eau\", \"nomb_sal_eau\", inplace = True)\n",
    "df_1.replace(\"Nombre de salles de bain\", \"nomb_sal_bain\", inplace = True)\n",
    "df_1.replace(\"Surface habitable\", \"hab_m2\", inplace = True)\n",
    "df_1.replace(\"Surface totale du terrain\", \"terr_m2\", inplace = True)\n",
    "df_1.replace(\"Type de bien\", \"type_bien\", inplace = True)\n",
    "df_1.replace(\"Type de vente\", \"type_vente\", inplace = True)\n",
    "df_1.replace(\"Nature du bien\", \"nature_bien\", inplace = True)\n",
    "df_1.replace(\"Charges honoraires\", \"honoraire\", inplace = True)\n",
    "df_1.replace(\"Ascenseur\", \"ascenceur\", inplace = True)\n",
    "df_1.replace(\"Exposition\", \"expo\", inplace = True)\n",
    "df_1.replace(\"Référence\", \"ref\", inplace = True)\n",
    "\n",
    "pivoted = df_1.pivot(index=['ad_id', 'time'], columns='dim', values='desc')\n",
    "pivoted = pivoted.reset_index()\n",
    "\n",
    "if 'nature_bien' in pivoted.columns:\n",
    "    pivoted['nature_bien'] = pivoted['nature_bien'].fillna(\"Aucun\")\n",
    "else :\n",
    "    pass\n",
    "\n",
    "if 'nature_bien' in pivoted.columns:\n",
    "    pivoted['nature_bien'] = pivoted['nature_bien'].fillna(\"Aucun\")\n",
    "else :\n",
    "    pass\n",
    "\n",
    "if 'nomb_piece' in pivoted.columns:\n",
    "    pivoted['nomb_piece'] = pivoted['nomb_piece'].fillna(0)\n",
    "\n",
    "else :\n",
    "    pass\n",
    "\n",
    "if 'type_vente' in pivoted.columns:\n",
    "    pivoted['type_vente'] =  pivoted[\"type_vente\"].fillna(\"Aucun\")\n",
    "else :\n",
    "    pass\n",
    "\n",
    "if 'hab_m2' in pivoted.columns :\n",
    "    pivoted['hab_m2'] = pivoted['hab_m2'].fillna(0).str.extract(r'(\\d+)').fillna(0).astype(int)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if 'terr_m2' in pivoted.columns :\n",
    "    pivoted['terr_m2'] = pivoted['terr_m2'].fillna(0).str.extract(r'(\\d+)').fillna(0).astype(int)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "if 'nomb_chambre' in pivoted.columns :\n",
    "    pivoted['nomb_chambre'] = pivoted['nomb_chambre'].fillna(0).str.extract(r'(\\d+)').fillna(0).astype(int)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "pivoted['post_code'] = pivoted['place'].str[-6:]\n",
    "pivoted['place'] =  pivoted['place'].str[:-6]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final = pivoted[[\"ad_id\", \"time\", \"type_bien\", \"hab_m2\", \"terr_m2\",\"nomb_piece\", \"nomb_chambre\",\"price\", \"place\",\"post_code\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price_follow_up = pivoted[[\"ad_id\", \"time\", \"price\"]].copy()\n",
    "df_price_follow_up[\"ad_id\"] = pd.to_numeric(df_price_follow_up[\"ad_id\"], errors='coerce')\n",
    "df_price_follow_up[\"price\"] = pd.to_numeric(df_price_follow_up[\"price\"], errors='coerce')\n",
    "df_price_follow_up['time'] = pd.to_datetime(df_price_follow_up['time'], format=\"%Y-%m-%d-%H:%M:%S\", errors='coerce')\n",
    "\n",
    "final['time'] = pd.to_datetime(final['time'], format=\"%Y-%m-%d-%H:%M:%S\", errors='coerce')\n",
    "final[\"ad_id\"] = pd.to_numeric(final[\"ad_id\"], errors='coerce')\n",
    "final[\"price\"] = pd.to_numeric(final[\"price\"], errors='coerce')\n",
    "final[\"hab_m2\"] = pd.to_numeric(final[\"hab_m2\"], errors='coerce')\n",
    "final[\"terr_m2\"] = pd.to_numeric(final[\"terr_m2\"], errors='coerce')\n",
    "final[\"nomb_piece\"] = pd.to_numeric(final[\"nomb_piece\"], errors='coerce')\n",
    "final[\"nomb_chambre\"] = pd.to_numeric(final[\"nomb_chambre\"], errors='coerce')\n",
    "final['ad_id'] = final['ad_id'].astype(str)\n",
    "\n",
    "final = final.dropna(subset=['type_bien'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65279644",
   "metadata": {},
   "source": [
    "# Load\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef08275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'XXXXX'\n",
    "database = 'XXX'\n",
    "username = 'XXXX'\n",
    "password = 'XXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505a693",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = (\n",
    "    f'DRIVER={{ODBC Driver 18 for SQL Server}};'\n",
    "    f'SERVER={server};'\n",
    "    f'DATABASE={database};'\n",
    "    f'UID={username};'\n",
    "    f'PWD={password};'\n",
    "    'Encrypt=yes;'\n",
    "    'TrustServerCertificate=no;'\n",
    "    'Connection Timeout=30;'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ceaf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = pyodbc.connect(connection_string)\n",
    "    print(\"✅ Connected to Azure SQL successfully.\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(\"❌ Connection failed:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d686a6",
   "metadata": {},
   "source": [
    "# Insert price follow up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection and cursor\n",
    "conn = pyodbc.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Example: inserting one row\n",
    "sql = \"\"\"\n",
    "INSERT INTO price_follow_up (ad_id, time, price)\n",
    "VALUES (?, ?, ?)\n",
    "\"\"\"\n",
    "rows_to_insert = []\n",
    "\n",
    "for _, row in df_price_follow_up.iterrows():\n",
    "    rows_to_insert.append((\n",
    "        row['ad_id'],\n",
    "        row['price'],\n",
    "        row['time'],\n",
    "        row['ad_id'],  # doublé pour le WHERE\n",
    "        row['time']   # doublé pour le WHERE\n",
    "    ))\n",
    "    \n",
    "    \n",
    "sql = \"\"\"\n",
    "INSERT INTO price_follow_up (ad_id, price, time)\n",
    "SELECT ?, ?, ?\n",
    "WHERE NOT EXISTS (\n",
    "    SELECT 1 FROM price_follow_up WHERE ad_id = ? AND time = ?\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(sql, rows_to_insert)\n",
    "conn.commit()\n",
    "\n",
    "print(\"✅ Rows inserted successfully.\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b6a28",
   "metadata": {},
   "source": [
    "# Inserting ads details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da842ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection and cursor\n",
    "conn = pyodbc.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "rows_to_insert = []\n",
    "\n",
    "for _, row in final.iterrows():\n",
    "    rows_to_insert.append((\n",
    "        row['ad_id'],\n",
    "        row['time'],\n",
    "        row['type_bien'],\n",
    "        row['hab_m2'], \n",
    "        row['terr_m2'], \n",
    "        row['nomb_piece'], \n",
    "        row['nomb_chambre'], \n",
    "        row['price'], \n",
    "        row['place'], \n",
    "        row['post_code']\n",
    "    ))\n",
    "    \n",
    "    \n",
    "sql = \"\"\"\n",
    "MERGE desc_ad AS target\n",
    "USING (SELECT ? AS ad_id, ? AS time, ? AS type_bien, ? AS hab_m2, ? AS terr_m2,\n",
    "              ? AS nomb_piece, ? AS nomb_chambre, ? AS price, ? AS place, ? AS post_code) AS source\n",
    "ON target.ad_id = source.ad_id\n",
    "\n",
    "WHEN MATCHED THEN \n",
    "    UPDATE SET \n",
    "        time = source.time,\n",
    "        type_bien = source.type_bien,\n",
    "        hab_m2 = source.hab_m2,\n",
    "        terr_m2 = source.terr_m2,\n",
    "        nomb_piece = source.nomb_piece,\n",
    "        nomb_chambre = source.nomb_chambre,\n",
    "        price = source.price,\n",
    "        place = source.place,\n",
    "        post_code = source.post_code\n",
    "\n",
    "WHEN NOT MATCHED THEN \n",
    "    INSERT (ad_id, time, type_bien, hab_m2, terr_m2, nomb_piece, nomb_chambre, price, place, post_code)\n",
    "    VALUES (source.ad_id, source.time, source.type_bien, source.hab_m2, source.terr_m2,\n",
    "            source.nomb_piece, source.nomb_chambre, source.price, source.place, source.post_code);\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(sql, rows_to_insert)\n",
    "conn.commit()\n",
    "\n",
    "print(\"✅ Rows inserted successfully.\")\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (immoproject)",
   "language": "python",
   "name": "immoproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
